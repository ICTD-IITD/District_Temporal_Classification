{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath  =\"/home/aygupt/Desktop/A.Seth Project/Landset Imagery/Output_Features_and_Labels/2011_districts_quant.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv (filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'censuscode', '1', '2', '3', '4', '5', '6', '7', '8',\n",
       "       ...\n",
       "       '111', '112', '113', '114', '115', '116', '117', '118', '119', '120'],\n",
       "      dtype='object', length=122)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"census_code\"] = df[\"censuscode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_groundtruth = \"/home/aygupt/Desktop/A.Seth Project/Landset Imagery/Output_Features_and_Labels/District - Ground Truth - 2011&2001.csv\"\n",
    "y1 = pd.read_csv(path_groundtruth)\n",
    "\n",
    "path_groundtruth = \"/home/aygupt/Desktop/A.Seth Project/Landset Imagery/Output_Features_and_Labels/FEMP&LIT.csv\"\n",
    "y2 = pd.read_csv(path_groundtruth)\n",
    "\n",
    "y3 = pd.merge(y1,y2,on ='census_code')\n",
    "final = pd.merge(df,y3, on='census_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 143)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final[[str(i) for i in range(1,121)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSET_2011  =>  0.6058216614020753\n",
      "BF_2011  =>  0.6276345848403747\n",
      "CHH_2011  =>  0.5591645437095373\n",
      "FC_2011  =>  0.5967390972453239\n",
      "MSL_2011  =>  0.6565472168262109\n",
      "MSW_2011  =>  0.7611163449992365\n",
      "LIT_2011  =>  0.5294685833646873\n",
      "FEMP_2011  =>  0.5829658736525701\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "l = ['ASSET_2011','BF_2011','CHH_2011','FC_2011','MSL_2011','MSW_2011','LIT_2011','FEMP_2011']\n",
    "for indicator in l :\n",
    "    y = final[[indicator]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(indicator,\" => \",f1_score(y_test.values.ravel(),y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSET_2011  =>  0.6999778221790999\n",
      "BF_2011  =>  0.6926565497994068\n",
      "CHH_2011  =>  0.6428045444982117\n",
      "FC_2011  =>  0.7680378811756364\n",
      "MSL_2011  =>  0.7191068759921712\n",
      "MSW_2011  =>  0.8321798201406894\n",
      "LIT_2001  =>  0.5976975405546834\n",
      "FEMP_2001  =>  0.6280203837807525\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "l = ['ASSET_2011','BF_2011','CHH_2011','FC_2011','MSL_2011','MSW_2011','LIT_2001','FEMP_2001']\n",
    "for indicator in l :\n",
    "    y = final[[indicator]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(indicator,\" => \",f1_score(y_test.values.ravel(),y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
